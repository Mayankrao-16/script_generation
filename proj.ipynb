{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5855\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "with open('episodes\\\\HP1.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab_list = sorted(set([re.sub('[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0-9]', '', i) for i in word_tokenize(text.lower()) if i[0].isalpha()]))\n",
    "vocab_list.pop(0)\n",
    "vocab = sorted(set(text))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)\n",
    "\n",
    "#print(vocab)\n",
    "#print(vocab_to_int)\n",
    "#print(int_to_vocab)\n",
    "\n",
    "#encoded contains the entire text, encoded character-wise. Example: MONICA: 29 56 ...etc where 29 is M and 56 is O\n",
    "#print(encoded)\n",
    "\n",
    "def get_batches(arr, batch_size, n_steps):\n",
    "    # Get the number of characters per batch and number of batches we can make\n",
    "    chars_per_batch = batch_size * n_steps\n",
    "    n_batches = len(arr)//chars_per_batch\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * chars_per_batch]\n",
    "    \n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y_temp = arr[:, n+1:n+n_steps+1]\n",
    "        \n",
    "        # For the very last batch, y will be one character short at the end of \n",
    "        # the sequences which breaks things. To get around this, I'll make an \n",
    "        # array of the appropriate size first, of all zeros, then add the targets.\n",
    "        # This will introduce a small artifact in the last batch, but it won't matter.\n",
    "        y = np.zeros(x.shape, dtype=x.dtype)\n",
    "        y[:,:y_temp.shape[1]] = y_temp\n",
    "        \n",
    "        yield x, y\n",
    "\n",
    "\n",
    "#batches = get_batches(encoded, 10, 50)\n",
    "#x,y = next(batches)\n",
    "\n",
    "#print(x,y)\n",
    "print(len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout'''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers'''\n",
    "    \n",
    "    #Build the LSTM Cell\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        # Use a basic LSTM cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        x: Input tensor\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # That is, the shape should be batch_size*num_steps rows by lstm_size columns\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # One-hot encode targets and reshape to match logits, one row per batch_size per step\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        \n",
    "        # Run each sequence step through the RNN and collect the outputs\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002ED96F05AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002ED96F05AC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002ED96F05AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002ED96F05AC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9A3B1508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9A3B1508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9A3B1508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9A3B1508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002ED971DDF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002ED971DDF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002ED971DDF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002ED971DDF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Epoch: 1/200...  Training Step: 50...  Training loss: 3.1779...  0.1000 sec/batch\n",
      "Epoch: 2/200...  Training Step: 100...  Training loss: 3.1416...  0.1000 sec/batch\n",
      "Epoch: 3/200...  Training Step: 150...  Training loss: 3.1237...  0.1370 sec/batch\n",
      "Epoch: 3/200...  Training Step: 200...  Training loss: 2.9573...  0.1000 sec/batch\n",
      "Epoch: 4/200...  Training Step: 250...  Training loss: 2.7559...  0.1000 sec/batch\n",
      "Epoch: 5/200...  Training Step: 300...  Training loss: 2.6160...  0.1000 sec/batch\n",
      "Epoch: 6/200...  Training Step: 350...  Training loss: 2.6230...  0.1020 sec/batch\n",
      "Epoch: 6/200...  Training Step: 400...  Training loss: 2.4779...  0.1020 sec/batch\n",
      "Epoch: 7/200...  Training Step: 450...  Training loss: 2.4507...  0.1010 sec/batch\n",
      "Epoch: 8/200...  Training Step: 500...  Training loss: 2.3909...  0.0990 sec/batch\n",
      "Epoch: 9/200...  Training Step: 550...  Training loss: 2.3812...  0.0990 sec/batch\n",
      "Epoch: 9/200...  Training Step: 600...  Training loss: 2.3517...  0.1000 sec/batch\n",
      "Epoch: 10/200...  Training Step: 650...  Training loss: 2.3342...  0.0990 sec/batch\n",
      "Epoch: 11/200...  Training Step: 700...  Training loss: 2.2823...  0.0990 sec/batch\n",
      "Epoch: 12/200...  Training Step: 750...  Training loss: 2.2717...  0.1010 sec/batch\n",
      "Epoch: 12/200...  Training Step: 800...  Training loss: 2.2892...  0.1000 sec/batch\n",
      "Epoch: 13/200...  Training Step: 850...  Training loss: 2.2309...  0.1000 sec/batch\n",
      "Epoch: 14/200...  Training Step: 900...  Training loss: 2.2181...  0.1980 sec/batch\n",
      "Epoch: 14/200...  Training Step: 950...  Training loss: 2.2146...  0.1000 sec/batch\n",
      "Epoch: 15/200...  Training Step: 1000...  Training loss: 2.2116...  0.1010 sec/batch\n",
      "Epoch: 16/200...  Training Step: 1050...  Training loss: 2.1657...  0.1000 sec/batch\n",
      "Epoch: 17/200...  Training Step: 1100...  Training loss: 2.1475...  0.2010 sec/batch\n",
      "Epoch: 17/200...  Training Step: 1150...  Training loss: 2.1433...  0.0990 sec/batch\n",
      "Epoch: 18/200...  Training Step: 1200...  Training loss: 2.1225...  0.1010 sec/batch\n",
      "Epoch: 19/200...  Training Step: 1250...  Training loss: 2.0831...  0.1000 sec/batch\n",
      "Epoch: 20/200...  Training Step: 1300...  Training loss: 2.0716...  0.1010 sec/batch\n",
      "Epoch: 20/200...  Training Step: 1350...  Training loss: 2.1035...  0.1020 sec/batch\n",
      "Epoch: 21/200...  Training Step: 1400...  Training loss: 2.0296...  0.1000 sec/batch\n",
      "Epoch: 22/200...  Training Step: 1450...  Training loss: 2.0476...  0.1010 sec/batch\n",
      "Epoch: 23/200...  Training Step: 1500...  Training loss: 2.0050...  0.1010 sec/batch\n",
      "Epoch: 23/200...  Training Step: 1550...  Training loss: 2.0063...  0.0990 sec/batch\n",
      "Epoch: 24/200...  Training Step: 1600...  Training loss: 2.0227...  0.0640 sec/batch\n",
      "Epoch: 25/200...  Training Step: 1650...  Training loss: 1.9942...  0.1000 sec/batch\n",
      "Epoch: 25/200...  Training Step: 1700...  Training loss: 2.0326...  0.1350 sec/batch\n",
      "Epoch: 26/200...  Training Step: 1750...  Training loss: 1.9839...  0.1380 sec/batch\n",
      "Epoch: 27/200...  Training Step: 1800...  Training loss: 1.9523...  0.1000 sec/batch\n",
      "Epoch: 28/200...  Training Step: 1850...  Training loss: 1.9492...  0.1010 sec/batch\n",
      "Epoch: 28/200...  Training Step: 1900...  Training loss: 1.9428...  0.1010 sec/batch\n",
      "Epoch: 29/200...  Training Step: 1950...  Training loss: 1.9330...  0.1000 sec/batch\n",
      "Epoch: 30/200...  Training Step: 2000...  Training loss: 1.8902...  0.1000 sec/batch\n",
      "Epoch: 31/200...  Training Step: 2050...  Training loss: 1.9412...  0.1010 sec/batch\n",
      "Epoch: 31/200...  Training Step: 2100...  Training loss: 1.8631...  0.1000 sec/batch\n",
      "Epoch: 32/200...  Training Step: 2150...  Training loss: 1.8683...  0.1000 sec/batch\n",
      "Epoch: 33/200...  Training Step: 2200...  Training loss: 1.8730...  0.1010 sec/batch\n",
      "Epoch: 34/200...  Training Step: 2250...  Training loss: 1.8646...  0.0990 sec/batch\n",
      "Epoch: 34/200...  Training Step: 2300...  Training loss: 1.8628...  0.1000 sec/batch\n",
      "Epoch: 35/200...  Training Step: 2350...  Training loss: 1.8542...  0.1360 sec/batch\n",
      "Epoch: 36/200...  Training Step: 2400...  Training loss: 1.8363...  0.0990 sec/batch\n",
      "Epoch: 37/200...  Training Step: 2450...  Training loss: 1.8316...  0.1010 sec/batch\n",
      "Epoch: 37/200...  Training Step: 2500...  Training loss: 1.8739...  0.1000 sec/batch\n",
      "Epoch: 38/200...  Training Step: 2550...  Training loss: 1.8480...  0.0990 sec/batch\n",
      "Epoch: 39/200...  Training Step: 2600...  Training loss: 1.8249...  0.0640 sec/batch\n",
      "Epoch: 39/200...  Training Step: 2650...  Training loss: 1.8454...  0.0990 sec/batch\n",
      "Epoch: 40/200...  Training Step: 2700...  Training loss: 1.8522...  0.1020 sec/batch\n",
      "Epoch: 41/200...  Training Step: 2750...  Training loss: 1.8465...  0.1000 sec/batch\n",
      "Epoch: 42/200...  Training Step: 2800...  Training loss: 1.8116...  0.0970 sec/batch\n",
      "Epoch: 42/200...  Training Step: 2850...  Training loss: 1.7981...  0.0980 sec/batch\n",
      "Epoch: 43/200...  Training Step: 2900...  Training loss: 1.8137...  0.0980 sec/batch\n",
      "Epoch: 44/200...  Training Step: 2950...  Training loss: 1.7726...  0.1000 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/200...  Training Step: 3000...  Training loss: 1.7675...  0.0970 sec/batch\n",
      "Epoch: 45/200...  Training Step: 3050...  Training loss: 1.8069...  0.1010 sec/batch\n",
      "Epoch: 46/200...  Training Step: 3100...  Training loss: 1.7515...  0.1020 sec/batch\n",
      "Epoch: 47/200...  Training Step: 3150...  Training loss: 1.7672...  0.0990 sec/batch\n",
      "Epoch: 48/200...  Training Step: 3200...  Training loss: 1.7489...  0.0990 sec/batch\n",
      "Epoch: 48/200...  Training Step: 3250...  Training loss: 1.7464...  0.1000 sec/batch\n",
      "Epoch: 49/200...  Training Step: 3300...  Training loss: 1.7704...  0.1000 sec/batch\n",
      "Epoch: 50/200...  Training Step: 3350...  Training loss: 1.7309...  0.1000 sec/batch\n",
      "Epoch: 50/200...  Training Step: 3400...  Training loss: 1.8050...  0.1000 sec/batch\n",
      "Epoch: 51/200...  Training Step: 3450...  Training loss: 1.7553...  0.1020 sec/batch\n",
      "Epoch: 52/200...  Training Step: 3500...  Training loss: 1.7196...  0.1010 sec/batch\n",
      "Epoch: 53/200...  Training Step: 3550...  Training loss: 1.7143...  0.1010 sec/batch\n",
      "Epoch: 53/200...  Training Step: 3600...  Training loss: 1.7139...  0.1010 sec/batch\n",
      "Epoch: 54/200...  Training Step: 3650...  Training loss: 1.7325...  0.0990 sec/batch\n",
      "Epoch: 55/200...  Training Step: 3700...  Training loss: 1.6876...  0.0980 sec/batch\n",
      "Epoch: 56/200...  Training Step: 3750...  Training loss: 1.7216...  0.0990 sec/batch\n",
      "Epoch: 56/200...  Training Step: 3800...  Training loss: 1.6818...  0.1000 sec/batch\n",
      "Epoch: 57/200...  Training Step: 3850...  Training loss: 1.6808...  0.1020 sec/batch\n",
      "Epoch: 58/200...  Training Step: 3900...  Training loss: 1.6922...  0.0990 sec/batch\n",
      "Epoch: 59/200...  Training Step: 3950...  Training loss: 1.6632...  0.0990 sec/batch\n",
      "Epoch: 59/200...  Training Step: 4000...  Training loss: 1.6864...  0.1020 sec/batch\n",
      "Epoch: 60/200...  Training Step: 4050...  Training loss: 1.6848...  0.1020 sec/batch\n",
      "Epoch: 61/200...  Training Step: 4100...  Training loss: 1.6715...  0.0990 sec/batch\n",
      "Epoch: 62/200...  Training Step: 4150...  Training loss: 1.6534...  0.0990 sec/batch\n",
      "Epoch: 62/200...  Training Step: 4200...  Training loss: 1.7057...  0.0990 sec/batch\n",
      "Epoch: 63/200...  Training Step: 4250...  Training loss: 1.6798...  0.1020 sec/batch\n",
      "Epoch: 64/200...  Training Step: 4300...  Training loss: 1.6617...  0.1020 sec/batch\n",
      "Epoch: 64/200...  Training Step: 4350...  Training loss: 1.6864...  0.0990 sec/batch\n",
      "Epoch: 65/200...  Training Step: 4400...  Training loss: 1.7147...  0.1000 sec/batch\n",
      "Epoch: 66/200...  Training Step: 4450...  Training loss: 1.7034...  0.1010 sec/batch\n",
      "Epoch: 67/200...  Training Step: 4500...  Training loss: 1.6608...  0.1000 sec/batch\n",
      "Epoch: 67/200...  Training Step: 4550...  Training loss: 1.6539...  0.1340 sec/batch\n",
      "Epoch: 68/200...  Training Step: 4600...  Training loss: 1.6759...  0.1019 sec/batch\n",
      "Epoch: 69/200...  Training Step: 4650...  Training loss: 1.6403...  0.1000 sec/batch\n",
      "Epoch: 70/200...  Training Step: 4700...  Training loss: 1.6374...  0.1020 sec/batch\n",
      "Epoch: 70/200...  Training Step: 4750...  Training loss: 1.6776...  0.1000 sec/batch\n",
      "Epoch: 71/200...  Training Step: 4800...  Training loss: 1.6263...  0.1010 sec/batch\n",
      "Epoch: 72/200...  Training Step: 4850...  Training loss: 1.6467...  0.1000 sec/batch\n",
      "Epoch: 73/200...  Training Step: 4900...  Training loss: 1.6162...  0.1000 sec/batch\n",
      "Epoch: 73/200...  Training Step: 4950...  Training loss: 1.6235...  0.0990 sec/batch\n",
      "Epoch: 74/200...  Training Step: 5000...  Training loss: 1.6227...  0.0980 sec/batch\n",
      "Epoch: 75/200...  Training Step: 5050...  Training loss: 1.6233...  0.1010 sec/batch\n",
      "Epoch: 75/200...  Training Step: 5100...  Training loss: 1.6997...  0.1060 sec/batch\n",
      "Epoch: 76/200...  Training Step: 5150...  Training loss: 1.6536...  0.0990 sec/batch\n",
      "Epoch: 77/200...  Training Step: 5200...  Training loss: 1.5969...  0.0990 sec/batch\n",
      "Epoch: 78/200...  Training Step: 5250...  Training loss: 1.5983...  0.1000 sec/batch\n",
      "Epoch: 78/200...  Training Step: 5300...  Training loss: 1.6154...  0.0990 sec/batch\n",
      "Epoch: 79/200...  Training Step: 5350...  Training loss: 1.6195...  0.1000 sec/batch\n",
      "Epoch: 80/200...  Training Step: 5400...  Training loss: 1.5826...  0.1010 sec/batch\n",
      "Epoch: 81/200...  Training Step: 5450...  Training loss: 1.6148...  0.1020 sec/batch\n",
      "Epoch: 81/200...  Training Step: 5500...  Training loss: 1.5707...  0.1010 sec/batch\n",
      "Epoch: 82/200...  Training Step: 5550...  Training loss: 1.5739...  0.1000 sec/batch\n",
      "Epoch: 83/200...  Training Step: 5600...  Training loss: 1.5876...  0.1000 sec/batch\n",
      "Epoch: 84/200...  Training Step: 5650...  Training loss: 1.5568...  0.0980 sec/batch\n",
      "Epoch: 84/200...  Training Step: 5700...  Training loss: 1.5909...  0.0990 sec/batch\n",
      "Epoch: 85/200...  Training Step: 5750...  Training loss: 1.5987...  0.1010 sec/batch\n",
      "Epoch: 86/200...  Training Step: 5800...  Training loss: 1.5714...  0.1020 sec/batch\n",
      "Epoch: 87/200...  Training Step: 5850...  Training loss: 1.5620...  0.0980 sec/batch\n",
      "Epoch: 87/200...  Training Step: 5900...  Training loss: 1.6316...  0.0990 sec/batch\n",
      "Epoch: 88/200...  Training Step: 5950...  Training loss: 1.5958...  0.0980 sec/batch\n",
      "Epoch: 89/200...  Training Step: 6000...  Training loss: 1.5732...  0.0990 sec/batch\n",
      "Epoch: 89/200...  Training Step: 6050...  Training loss: 1.5943...  0.1000 sec/batch\n",
      "Epoch: 90/200...  Training Step: 6100...  Training loss: 1.6117...  0.0640 sec/batch\n",
      "Epoch: 91/200...  Training Step: 6150...  Training loss: 1.6011...  0.1000 sec/batch\n",
      "Epoch: 92/200...  Training Step: 6200...  Training loss: 1.5631...  0.1020 sec/batch\n",
      "Epoch: 92/200...  Training Step: 6250...  Training loss: 1.5708...  0.1000 sec/batch\n",
      "Epoch: 93/200...  Training Step: 6300...  Training loss: 1.5830...  0.1000 sec/batch\n",
      "Epoch: 94/200...  Training Step: 6350...  Training loss: 1.5633...  0.0660 sec/batch\n",
      "Epoch: 95/200...  Training Step: 6400...  Training loss: 1.5588...  0.0990 sec/batch\n",
      "Epoch: 95/200...  Training Step: 6450...  Training loss: 1.5849...  0.0650 sec/batch\n",
      "Epoch: 96/200...  Training Step: 6500...  Training loss: 1.5479...  0.0980 sec/batch\n",
      "Epoch: 97/200...  Training Step: 6550...  Training loss: 1.5655...  0.1030 sec/batch\n",
      "Epoch: 98/200...  Training Step: 6600...  Training loss: 1.5509...  0.1000 sec/batch\n",
      "Epoch: 98/200...  Training Step: 6650...  Training loss: 1.5453...  0.0990 sec/batch\n",
      "Epoch: 99/200...  Training Step: 6700...  Training loss: 1.5473...  0.1000 sec/batch\n",
      "Epoch: 100/200...  Training Step: 6750...  Training loss: 1.5401...  0.1000 sec/batch\n",
      "Epoch: 100/200...  Training Step: 6800...  Training loss: 1.6231...  0.1000 sec/batch\n",
      "Epoch: 101/200...  Training Step: 6850...  Training loss: 1.5634...  0.1010 sec/batch\n",
      "Epoch: 102/200...  Training Step: 6900...  Training loss: 1.5184...  0.0990 sec/batch\n",
      "Epoch: 103/200...  Training Step: 6950...  Training loss: 1.5305...  0.1000 sec/batch\n",
      "Epoch: 103/200...  Training Step: 7000...  Training loss: 1.5443...  0.1000 sec/batch\n",
      "Epoch: 104/200...  Training Step: 7050...  Training loss: 1.5490...  0.1010 sec/batch\n",
      "Epoch: 105/200...  Training Step: 7100...  Training loss: 1.5043...  0.1010 sec/batch\n",
      "Epoch: 106/200...  Training Step: 7150...  Training loss: 1.5430...  0.0990 sec/batch\n",
      "Epoch: 106/200...  Training Step: 7200...  Training loss: 1.4925...  0.1010 sec/batch\n",
      "Epoch: 107/200...  Training Step: 7250...  Training loss: 1.5038...  0.1000 sec/batch\n",
      "Epoch: 108/200...  Training Step: 7300...  Training loss: 1.5152...  0.1010 sec/batch\n",
      "Epoch: 109/200...  Training Step: 7350...  Training loss: 1.4845...  0.1020 sec/batch\n",
      "Epoch: 109/200...  Training Step: 7400...  Training loss: 1.5250...  0.0990 sec/batch\n",
      "Epoch: 110/200...  Training Step: 7450...  Training loss: 1.5104...  0.1000 sec/batch\n",
      "Epoch: 111/200...  Training Step: 7500...  Training loss: 1.5076...  0.0990 sec/batch\n",
      "Epoch: 112/200...  Training Step: 7550...  Training loss: 1.5034...  0.0990 sec/batch\n",
      "Epoch: 112/200...  Training Step: 7600...  Training loss: 1.5516...  0.1000 sec/batch\n",
      "Epoch: 113/200...  Training Step: 7650...  Training loss: 1.5239...  0.0990 sec/batch\n",
      "Epoch: 114/200...  Training Step: 7700...  Training loss: 1.4974...  0.1000 sec/batch\n",
      "Epoch: 114/200...  Training Step: 7750...  Training loss: 1.5280...  0.1010 sec/batch\n",
      "Epoch: 115/200...  Training Step: 7800...  Training loss: 1.5541...  0.1010 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116/200...  Training Step: 7850...  Training loss: 1.5540...  0.0989 sec/batch\n",
      "Epoch: 117/200...  Training Step: 7900...  Training loss: 1.5043...  0.0990 sec/batch\n",
      "Epoch: 117/200...  Training Step: 7950...  Training loss: 1.5246...  0.1000 sec/batch\n",
      "Epoch: 118/200...  Training Step: 8000...  Training loss: 1.5410...  0.1000 sec/batch\n",
      "Epoch: 119/200...  Training Step: 8050...  Training loss: 1.5035...  0.1000 sec/batch\n",
      "Epoch: 120/200...  Training Step: 8100...  Training loss: 1.4969...  0.1000 sec/batch\n",
      "Epoch: 120/200...  Training Step: 8150...  Training loss: 1.5309...  0.0620 sec/batch\n",
      "Epoch: 121/200...  Training Step: 8200...  Training loss: 1.4935...  0.1010 sec/batch\n",
      "Epoch: 122/200...  Training Step: 8250...  Training loss: 1.5184...  0.1000 sec/batch\n",
      "Epoch: 123/200...  Training Step: 8300...  Training loss: 1.4855...  0.0990 sec/batch\n",
      "Epoch: 123/200...  Training Step: 8350...  Training loss: 1.5054...  0.0990 sec/batch\n",
      "Epoch: 124/200...  Training Step: 8400...  Training loss: 1.5003...  0.1000 sec/batch\n",
      "Epoch: 125/200...  Training Step: 8450...  Training loss: 1.4925...  0.0990 sec/batch\n",
      "Epoch: 125/200...  Training Step: 8500...  Training loss: 1.5920...  0.1010 sec/batch\n",
      "Epoch: 126/200...  Training Step: 8550...  Training loss: 1.5148...  0.0630 sec/batch\n",
      "Epoch: 127/200...  Training Step: 8600...  Training loss: 1.4644...  0.1000 sec/batch\n",
      "Epoch: 128/200...  Training Step: 8650...  Training loss: 1.4768...  0.0990 sec/batch\n",
      "Epoch: 128/200...  Training Step: 8700...  Training loss: 1.5064...  0.0650 sec/batch\n",
      "Epoch: 129/200...  Training Step: 8750...  Training loss: 1.5105...  0.1000 sec/batch\n",
      "Epoch: 130/200...  Training Step: 8800...  Training loss: 1.4586...  0.1020 sec/batch\n",
      "Epoch: 131/200...  Training Step: 8850...  Training loss: 1.4971...  0.1010 sec/batch\n",
      "Epoch: 131/200...  Training Step: 8900...  Training loss: 1.4595...  0.1000 sec/batch\n",
      "Epoch: 132/200...  Training Step: 8950...  Training loss: 1.4638...  0.1000 sec/batch\n",
      "Epoch: 133/200...  Training Step: 9000...  Training loss: 1.4719...  0.1000 sec/batch\n",
      "Epoch: 134/200...  Training Step: 9050...  Training loss: 1.4459...  0.1000 sec/batch\n",
      "Epoch: 134/200...  Training Step: 9100...  Training loss: 1.4798...  0.0990 sec/batch\n",
      "Epoch: 135/200...  Training Step: 9150...  Training loss: 1.4783...  0.1000 sec/batch\n",
      "Epoch: 136/200...  Training Step: 9200...  Training loss: 1.4603...  0.1000 sec/batch\n",
      "Epoch: 137/200...  Training Step: 9250...  Training loss: 1.4650...  0.0990 sec/batch\n",
      "Epoch: 137/200...  Training Step: 9300...  Training loss: 1.5015...  0.0990 sec/batch\n",
      "Epoch: 138/200...  Training Step: 9350...  Training loss: 1.4741...  0.0650 sec/batch\n",
      "Epoch: 139/200...  Training Step: 9400...  Training loss: 1.4757...  0.1010 sec/batch\n",
      "Epoch: 139/200...  Training Step: 9450...  Training loss: 1.4770...  0.0990 sec/batch\n",
      "Epoch: 140/200...  Training Step: 9500...  Training loss: 1.4958...  0.1010 sec/batch\n",
      "Epoch: 141/200...  Training Step: 9550...  Training loss: 1.5169...  0.1010 sec/batch\n",
      "Epoch: 142/200...  Training Step: 9600...  Training loss: 1.4788...  0.1010 sec/batch\n",
      "Epoch: 142/200...  Training Step: 9650...  Training loss: 1.4777...  0.1010 sec/batch\n",
      "Epoch: 143/200...  Training Step: 9700...  Training loss: 1.4872...  0.1000 sec/batch\n",
      "Epoch: 144/200...  Training Step: 9750...  Training loss: 1.4518...  0.1010 sec/batch\n",
      "Epoch: 145/200...  Training Step: 9800...  Training loss: 1.4620...  0.2000 sec/batch\n",
      "Epoch: 145/200...  Training Step: 9850...  Training loss: 1.4877...  0.0990 sec/batch\n",
      "Epoch: 146/200...  Training Step: 9900...  Training loss: 1.4450...  0.0980 sec/batch\n",
      "Epoch: 147/200...  Training Step: 9950...  Training loss: 1.4806...  0.0990 sec/batch\n",
      "Epoch: 148/200...  Training Step: 10000...  Training loss: 1.4579...  0.0990 sec/batch\n",
      "Epoch: 148/200...  Training Step: 10050...  Training loss: 1.4649...  0.0990 sec/batch\n",
      "Epoch: 149/200...  Training Step: 10100...  Training loss: 1.4636...  0.1000 sec/batch\n",
      "Epoch: 150/200...  Training Step: 10150...  Training loss: 1.4576...  0.1020 sec/batch\n",
      "Epoch: 150/200...  Training Step: 10200...  Training loss: 1.5569...  0.1380 sec/batch\n",
      "Epoch: 151/200...  Training Step: 10250...  Training loss: 1.4844...  0.1000 sec/batch\n",
      "Epoch: 152/200...  Training Step: 10300...  Training loss: 1.4269...  0.1000 sec/batch\n",
      "Epoch: 153/200...  Training Step: 10350...  Training loss: 1.4341...  0.0640 sec/batch\n",
      "Epoch: 153/200...  Training Step: 10400...  Training loss: 1.4850...  0.1000 sec/batch\n",
      "Epoch: 154/200...  Training Step: 10450...  Training loss: 1.4782...  0.1010 sec/batch\n",
      "Epoch: 155/200...  Training Step: 10500...  Training loss: 1.4219...  0.1000 sec/batch\n",
      "Epoch: 156/200...  Training Step: 10550...  Training loss: 1.4600...  0.1990 sec/batch\n",
      "Epoch: 156/200...  Training Step: 10600...  Training loss: 1.4323...  0.1000 sec/batch\n",
      "Epoch: 157/200...  Training Step: 10650...  Training loss: 1.4307...  0.1000 sec/batch\n",
      "Epoch: 158/200...  Training Step: 10700...  Training loss: 1.4522...  0.0990 sec/batch\n",
      "Epoch: 159/200...  Training Step: 10750...  Training loss: 1.4104...  0.0990 sec/batch\n",
      "Epoch: 159/200...  Training Step: 10800...  Training loss: 1.4563...  0.1000 sec/batch\n",
      "Epoch: 160/200...  Training Step: 10850...  Training loss: 1.4573...  0.1000 sec/batch\n",
      "Epoch: 161/200...  Training Step: 10900...  Training loss: 1.4368...  0.1010 sec/batch\n",
      "Epoch: 162/200...  Training Step: 10950...  Training loss: 1.4351...  0.1010 sec/batch\n",
      "Epoch: 162/200...  Training Step: 11000...  Training loss: 1.4765...  0.1000 sec/batch\n",
      "Epoch: 163/200...  Training Step: 11050...  Training loss: 1.4511...  0.1000 sec/batch\n",
      "Epoch: 164/200...  Training Step: 11100...  Training loss: 1.4344...  0.1000 sec/batch\n",
      "Epoch: 164/200...  Training Step: 11150...  Training loss: 1.4608...  0.1000 sec/batch\n",
      "Epoch: 165/200...  Training Step: 11200...  Training loss: 1.4857...  0.1000 sec/batch\n",
      "Epoch: 166/200...  Training Step: 11250...  Training loss: 1.4722...  0.1390 sec/batch\n",
      "Epoch: 167/200...  Training Step: 11300...  Training loss: 1.4317...  0.0990 sec/batch\n",
      "Epoch: 167/200...  Training Step: 11350...  Training loss: 1.4607...  0.1000 sec/batch\n",
      "Epoch: 168/200...  Training Step: 11400...  Training loss: 1.4623...  0.1010 sec/batch\n",
      "Epoch: 169/200...  Training Step: 11450...  Training loss: 1.4464...  0.1000 sec/batch\n",
      "Epoch: 170/200...  Training Step: 11500...  Training loss: 1.4323...  0.1010 sec/batch\n",
      "Epoch: 170/200...  Training Step: 11550...  Training loss: 1.4595...  0.0990 sec/batch\n",
      "Epoch: 171/200...  Training Step: 11600...  Training loss: 1.4399...  0.1000 sec/batch\n",
      "Epoch: 172/200...  Training Step: 11650...  Training loss: 1.4573...  0.0990 sec/batch\n",
      "Epoch: 173/200...  Training Step: 11700...  Training loss: 1.4168...  0.1020 sec/batch\n",
      "Epoch: 173/200...  Training Step: 11750...  Training loss: 1.4445...  0.1010 sec/batch\n",
      "Epoch: 174/200...  Training Step: 11800...  Training loss: 1.4424...  0.1390 sec/batch\n",
      "Epoch: 175/200...  Training Step: 11850...  Training loss: 1.4293...  0.1370 sec/batch\n",
      "Epoch: 175/200...  Training Step: 11900...  Training loss: 1.5349...  0.1000 sec/batch\n",
      "Epoch: 176/200...  Training Step: 11950...  Training loss: 1.4537...  0.1000 sec/batch\n",
      "Epoch: 177/200...  Training Step: 12000...  Training loss: 1.4049...  0.0980 sec/batch\n",
      "Epoch: 178/200...  Training Step: 12050...  Training loss: 1.4334...  0.0990 sec/batch\n",
      "Epoch: 178/200...  Training Step: 12100...  Training loss: 1.4583...  0.0990 sec/batch\n",
      "Epoch: 179/200...  Training Step: 12150...  Training loss: 1.4443...  0.1000 sec/batch\n",
      "Epoch: 180/200...  Training Step: 12200...  Training loss: 1.3994...  0.0990 sec/batch\n",
      "Epoch: 181/200...  Training Step: 12250...  Training loss: 1.4515...  0.1010 sec/batch\n",
      "Epoch: 181/200...  Training Step: 12300...  Training loss: 1.3989...  0.0980 sec/batch\n",
      "Epoch: 182/200...  Training Step: 12350...  Training loss: 1.4169...  0.1000 sec/batch\n",
      "Epoch: 183/200...  Training Step: 12400...  Training loss: 1.4309...  0.1000 sec/batch\n",
      "Epoch: 184/200...  Training Step: 12450...  Training loss: 1.3788...  0.1000 sec/batch\n",
      "Epoch: 184/200...  Training Step: 12500...  Training loss: 1.4173...  0.1010 sec/batch\n",
      "Epoch: 185/200...  Training Step: 12550...  Training loss: 1.4210...  0.1330 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186/200...  Training Step: 12600...  Training loss: 1.4023...  0.1010 sec/batch\n",
      "Epoch: 187/200...  Training Step: 12650...  Training loss: 1.4200...  0.1010 sec/batch\n",
      "Epoch: 187/200...  Training Step: 12700...  Training loss: 1.4602...  0.0990 sec/batch\n",
      "Epoch: 188/200...  Training Step: 12750...  Training loss: 1.4252...  0.1000 sec/batch\n",
      "Epoch: 189/200...  Training Step: 12800...  Training loss: 1.4101...  0.1000 sec/batch\n",
      "Epoch: 189/200...  Training Step: 12850...  Training loss: 1.4347...  0.1010 sec/batch\n",
      "Epoch: 190/200...  Training Step: 12900...  Training loss: 1.4522...  0.0980 sec/batch\n",
      "Epoch: 191/200...  Training Step: 12950...  Training loss: 1.4448...  0.1000 sec/batch\n",
      "Epoch: 192/200...  Training Step: 13000...  Training loss: 1.4209...  0.1010 sec/batch\n",
      "Epoch: 192/200...  Training Step: 13050...  Training loss: 1.4245...  0.1000 sec/batch\n",
      "Epoch: 193/200...  Training Step: 13100...  Training loss: 1.4212...  0.0990 sec/batch\n",
      "Epoch: 194/200...  Training Step: 13150...  Training loss: 1.4122...  0.1000 sec/batch\n",
      "Epoch: 195/200...  Training Step: 13200...  Training loss: 1.4128...  0.1010 sec/batch\n",
      "Epoch: 195/200...  Training Step: 13250...  Training loss: 1.4399...  0.1020 sec/batch\n",
      "Epoch: 196/200...  Training Step: 13300...  Training loss: 1.4033...  0.1010 sec/batch\n",
      "Epoch: 197/200...  Training Step: 13350...  Training loss: 1.4294...  0.1000 sec/batch\n",
      "Epoch: 198/200...  Training Step: 13400...  Training loss: 1.4050...  0.1010 sec/batch\n",
      "Epoch: 198/200...  Training Step: 13450...  Training loss: 1.4254...  0.1020 sec/batch\n",
      "Epoch: 199/200...  Training Step: 13500...  Training loss: 1.4162...  0.1010 sec/batch\n",
      "Epoch: 200/200...  Training Step: 13550...  Training loss: 1.4241...  0.0990 sec/batch\n",
      "Epoch: 200/200...  Training Step: 13600...  Training loss: 1.5032...  0.1000 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "# Print losses every N interations\n",
    "print_every_n = 50\n",
    "\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = 50\n",
    "lstm_size = 128\n",
    "num_layers = 2\n",
    "learning_rate =0.001\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: 0.6,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            if (counter % print_every_n == 0):\n",
    "                end = time.time()\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(counter),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints\\\\i13600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i1000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i1200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i1400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i1600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i1800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i2000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i2200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i2400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i2600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i2800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i3000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i3200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i3400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i3600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i3800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i4000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i4200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i4400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i4600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i4800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i5000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i5200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i5400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i5600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i5800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i6000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i6200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i6400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i6600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i6800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i7000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i7200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i7400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i7600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i7800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i8000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i8200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i8400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i8600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i8800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i9000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i9200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i9400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i9600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i9800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i10000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i10200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i10400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i10600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i10800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i11000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i11200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i11400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i11600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i11800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i12000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i12200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i12400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i12600_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i12800_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i13000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i13200_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i13400_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i13600_l128.ckpt\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints\\\\i13600_l128.ckpt'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDistDP(str1, str2, m, n): \n",
    "    dp = [[0 for x in range(n+1)] for x in range(m+1)] \n",
    "    for i in range(m+1): \n",
    "        for j in range(n+1): \n",
    "            if i == 0: \n",
    "                dp[i][j] = j    \n",
    "            elif j == 0: \n",
    "                dp[i][j] = i    \n",
    "            elif str1[i-1] == str2[j-1]: \n",
    "                dp[i][j] = dp[i-1][j-1] \n",
    "            else: \n",
    "                dp[i][j] = 1 + min(dp[i][j-1],dp[i-1][j],dp[i-1][j-1])    \n",
    "    return dp[m][n] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(word1,word2):\n",
    "    return len(set(word1).intersection(set(word2))) / len(set(word1).union(set(word2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strcmp(word1,word2):\n",
    "    return abs(len(word1) - len(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_wrapper(word):\n",
    "\n",
    "    l1=[]\n",
    "    word = re.sub('[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0-9]', '', word)\n",
    "    for i in vocab_list:\n",
    "        edit_dist = editDistDP(i,word,len(i),len(word))\n",
    "        l1.append((strcmp(i,word),edit_dist,jaccard_similarity(i,word),i,word))\n",
    "    return sorted([i for i in l1 if i[0]<3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untokenize(words):\n",
    "    \"\"\"\n",
    "    Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    punctuation and spaces to the places that people expect them to be.\n",
    "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    except for line breaks.\n",
    "    \"\"\"\n",
    "    text = ' '.join(words)\n",
    "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
    "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "         \"can not\", \"cannot\")\n",
    "    step6 = step5.replace(\" ` \", \" '\")\n",
    "    return step6.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002EE9A67EB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002EE9A67EB48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002EE9A67EB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002EE9A67EB48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5A088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5A088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5A088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5A088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5AA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5AA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5AA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002EE9BF5AA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\i13600_l128.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp = sample(checkpoint, 10000, lstm_size, len(vocab), prime=\"THE MIRROR OF ERISED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fp = open(\"expected_output4\",\"w\")\n",
    "fp.write(samp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "backupsamp = copy.deepcopy(samp)\n",
    "backupsamp = word_tokenize(backupsamp)\n",
    "for i in range(len(backupsamp)):\n",
    "    if backupsamp[i].lower() not in vocab_list and len(backupsamp[i].lower())>1:\n",
    "        backupsamp[i] = min_edit_wrapper(backupsamp[i].lower())[0][-2]\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "backupsamp2 = untokenize(backupsamp)\n",
    "fp = open(\"output4\",\"w\")\n",
    "fp.write(backupsamp2)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
