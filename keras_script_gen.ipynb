{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NDy4iA0xZ9Ru",
    "outputId": "e60ef1bc-e9db-49f2-d395-7e090e3fb6ed",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  3733\n",
      "nb sequences: 40777\n",
      "Build LSTM model.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "model built!\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 512)               8171520   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3733)              1915029   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3733)              0         \n",
      "=================================================================\n",
      "Total params: 10,086,549\n",
      "Trainable params: 10,086,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\mayan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 40369 samples, validate on 408 samples\n",
      "Epoch 1/50\n",
      "40369/40369 [==============================] - 161s 4ms/step - loss: 6.3550 - categorical_accuracy: 0.0510 - val_loss: 6.0381 - val_categorical_accuracy: 0.0833\n",
      "Epoch 2/50\n",
      "40369/40369 [==============================] - 155s 4ms/step - loss: 5.8264 - categorical_accuracy: 0.0875 - val_loss: 5.9484 - val_categorical_accuracy: 0.0931\n",
      "Epoch 3/50\n",
      "40369/40369 [==============================] - 158s 4ms/step - loss: 5.6087 - categorical_accuracy: 0.1090 - val_loss: 5.8761 - val_categorical_accuracy: 0.1275\n",
      "Epoch 4/50\n",
      "40369/40369 [==============================] - 157s 4ms/step - loss: 5.3876 - categorical_accuracy: 0.1364 - val_loss: 5.8572 - val_categorical_accuracy: 0.1446\n",
      "Epoch 5/50\n",
      "40369/40369 [==============================] - 156s 4ms/step - loss: 5.1652 - categorical_accuracy: 0.1572 - val_loss: 5.7989 - val_categorical_accuracy: 0.1618\n",
      "Epoch 6/50\n",
      "40369/40369 [==============================] - 157s 4ms/step - loss: 4.9518 - categorical_accuracy: 0.1766 - val_loss: 5.7743 - val_categorical_accuracy: 0.1691\n",
      "Epoch 7/50\n",
      "40369/40369 [==============================] - 157s 4ms/step - loss: 4.7265 - categorical_accuracy: 0.1897 - val_loss: 5.8299 - val_categorical_accuracy: 0.1814\n",
      "Epoch 8/50\n",
      "40369/40369 [==============================] - 157s 4ms/step - loss: 4.5517 - categorical_accuracy: 0.2035 - val_loss: 5.8274 - val_categorical_accuracy: 0.1887\n",
      "Epoch 9/50\n",
      "40369/40369 [==============================] - 155s 4ms/step - loss: 4.2899 - categorical_accuracy: 0.2230 - val_loss: 5.8423 - val_categorical_accuracy: 0.1863\n",
      "Epoch 10/50\n",
      "40369/40369 [==============================] - 155s 4ms/step - loss: 4.0527 - categorical_accuracy: 0.2412 - val_loss: 5.8758 - val_categorical_accuracy: 0.1985\n",
      "loading vocabulary...\n",
      "loading model...\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Generating text with the following seed: \"a a a a a a a a a a a a a a a a a a a a a a a Invisibility Cloak on top of the tower\"\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Invisibility'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c7377959935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;31m#print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Invisibility'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM, Input, Flatten, Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "#import spacy, and french model\n",
    "import spacy\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "save_dir = 'models' # directory to store models\n",
    "seq_length = 30 # sequence length\n",
    "sequences_step = 1 #step to create sequences\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "try:\n",
    "    vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "except:\n",
    "    print(\"Vocab file does not exist\")\n",
    "    pass\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "def create_wordlist(doc):\n",
    "    wl = []\n",
    "    for word in doc:\n",
    "        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "            wl.append(word.text.lower())\n",
    "    return wl\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "input_file = 'episodes\\\\HP1.txt'\n",
    "wordlist = []\n",
    "#read data\n",
    "with codecs.open(input_file, \"r\") as f:\n",
    "  data = f.read()\n",
    "#create sentences\n",
    "doc = nlp(data)\n",
    "wl = create_wordlist(doc)\n",
    "wordlist = wordlist + wl\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# count the number of words\n",
    "word_counts = collections.Counter(wordlist)\n",
    "\n",
    "# Mapping from index to word : that's the vocabulary\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "#size of the vocabulary\n",
    "vocab_size = len(words)\n",
    "print(\"vocab size: \", vocab_size)\n",
    "\n",
    "#save the words and vocabulary\n",
    "with open(os.path.join(vocab_file), 'wb') as f:\n",
    "    cPickle.dump((words, vocab, vocabulary_inv), f)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "#create sequences\n",
    "sequences = []\n",
    "next_words = []\n",
    "for i in range(0, len(wordlist) - seq_length, sequences_step):\n",
    "    sequences.append(wordlist[i: i + seq_length])\n",
    "    next_words.append(wordlist[i + seq_length])\n",
    "\n",
    "print('nb sequences:', len(sequences))\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        X[i, t, vocab[word]] = 1\n",
    "    y[i, vocab[next_words[i]]] = 1\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "def bidirectional_lstm_model(seq_length, vocab_size):\n",
    "    print('Build LSTM model.')\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n",
    "    print(\"model built!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "rnn_size = 256 # size of RNN\n",
    "batch_size = 32 # minibatch size\n",
    "seq_length = 30 # sequence length\n",
    "num_epochs = 50 # number of epochs\n",
    "learning_rate = 0.001 #learning rate\n",
    "sequences_step = 1 #step to create sequences\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "md = bidirectional_lstm_model(seq_length, vocab_size)\n",
    "md.summary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#fit the model\n",
    "callbacks=[EarlyStopping(patience=4, monitor='val_loss'),\n",
    "           ModelCheckpoint(filepath=save_dir + \"/\" + 'my_model_gen_sentences_lstm.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n",
    "                           monitor='val_loss', verbose=0, mode='auto', period=2)]\n",
    "history = md.fit(X, y,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True,\n",
    "                 epochs=num_epochs,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_split=0.01)\n",
    "\n",
    "\n",
    "\n",
    "#save the modelnn\n",
    "md.save(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "#load vocabulary\n",
    "print(\"loading vocabulary...\")\n",
    "try:\n",
    "    vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "    with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
    "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = len(words)\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "print(\"loading model...\")\n",
    "model = load_model(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def untokenize(words):\n",
    "    \"\"\"\n",
    "    Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    punctuation and spaces to the places that people expect them to be.\n",
    "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    except for line breaks.\n",
    "    \"\"\"\n",
    "    text = ' '.join(words)\n",
    "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
    "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "         \"can not\", \"cannot\")\n",
    "    step6 = step5.replace(\" ` \", \" '\")\n",
    "    return step6.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30987,
     "status": "ok",
     "timestamp": 1574767207793,
     "user": {
      "displayName": "Rhiya Ramesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBurNB5q--KOwuDFdNjTyjBLk_pDi4Q22qhnoOelA=s64",
      "userId": "00464787936944995762"
     },
     "user_tz": -330
    },
    "id": "-SXWK3zyb-ov",
    "outputId": "6bdb87fe-2b5a-45c3-aee3-249e9aa80bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". i'm you, said ron. i'm a a a a few a a a, and and a a little - a a of the mirror, and the the mirror, and he'dn't be a the, and the mirror, and he couldn't be a very a, and he had been a the mirror, and they had been a the mirror, and he wasn't be a the hat, and the troll, and the first years. he was a in the mirror, and he'd been a a, and the first years. he wasn't be. i'm you, said ron. he'd have been a nimbus two thousand. i'm you, said ron, i'm you, said ron. i'm going to be a a a a the mirror, and he was going to be. i'm you? said, said ron, harry, said ron, he said. i'm you, said ron. i'm what you're going to be your. i'm you? i'm you, said ron. i'm you, said ron, harry's, but i'm i'm you, said ron. i'm you, said ron. i'm you, said ron, harry's got to the the mirror. i'm you, you're going to be a your, said ron. i'm you've got to get a the mirror, but you're to be a the, said ron, and ron, and ron, and the the head of the hall, and the the hat, and the hall, and the hall was the great hall, and the hall, and the hall, and the hat, the hat and the hat, and the hall was the hall, and the first years. they were a a the hat, and the hat, and the hat, and the mirror, and the a the troll, and a a a a, and the hat and the hat and the hat. harry had been the mirror, he wasn't going to be. i'm you're not to be the hat, said ron. i'm you? i'm you, said ron, i'm you, you're not to be you. i'm you, said ron. i'm you?\n"
     ]
    }
   ],
   "source": [
    "#initiate sentences\n",
    "seed_sentences = \"They would have felt sorry for Hagrid when the time came for him to say good bye to Norbert if they had not been so worried\"\n",
    "generated = ''\n",
    "sentence = []\n",
    "for i in range (seq_length):\n",
    "    sentence.append(\"a\")\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "seed = word_tokenize(seed_sentences)\n",
    "\n",
    "for i in range(len(seed)):\n",
    "    sentence[seq_length-i-1]=seed[len(seed)-i-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "words_number = 500\n",
    "generated =[]\n",
    "#generate the text\n",
    "for i in range(words_number):\n",
    "    #create the vector\n",
    "    x = np.zeros((1, seq_length, vocab_size))\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[0, t, vocab[word.lower()]] = 1.\n",
    "    #print(x.shape)\n",
    "\n",
    "    #calculate next word\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, 0.1)\n",
    "    next_word = vocabulary_inv[next_index]\n",
    "\n",
    "    #add the next word to the text\n",
    "    generated.append(next_word)\n",
    "    # shift the sentence by one, and and the next word at its end\n",
    "    sentence = sentence[1:] + [next_word]\n",
    "\n",
    "print(\" \".join(untokenize(generated).replace(\"\\\"\",\"\").split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". i'm no, said ron, hagrid's your sorcerer's stone, he'dn't a the. hagrid, the yelled, but he's must be remembrall. he asked ron, but what's he's than, said wood. i'm to the remembrall that, you've got all for the team. don't want to you, said hermione. i've got the see you, said ron. you're too not to your i think i'm in the team, said ron. he said. oh, you're not me to you've got to get. he is it. i'm i know you? well, said ron, harry's time to have to be of the back. i'm' - i've got the door, said ron, and harry had had to percy on the gryffindor, but it's the too. harry's were the head, said ron, harry at once. the new. he's really've got to the the dragon's. you'll have to have been a a this, and snape wasn't have the the in a the few and that was three of the gryffindor. i'm this, you'd be were no. ron, said ron. i'll not him, said ron. i'm you get a it. i'm me - you're i've got to be i'm, said ron. i'm your you, said ron. i'mn't come, said harry. i'm i'm' you, said ron, i'm you, you're going to be the house the first years in the mirror of and then i'll be the. i don't want to a know, said ron. i'm, said ron. how to you, you've got to get a the away and year, that's the midnight your high, up? said ron, you've got the head, said ron, the gryffindor, said ron. i'm about you, said ron, harry told ron. what are you? said, hagrid's us the you're an''. said, said harry. ron, said ron, what i'm the other, said hagrid. you've got to very going to tell what about it, you'll be you? i'll get me for you, said harry, harry's be a his own. you've got to hear you will be you've got about gryffindor, said ron, ron as they tree. then, but the harry, was, but i've got to it, then, but they couldn't for? said, said harry. the house on the the team, , but' harry's got to the and. so you could have have to be charlie to be of the brooms. i'm trying to be going to be the high, harry and harry looked him. he couldn't a a you, you've got to a - of the head, and ron had been this. he hadn't think they were, the the house. i'm he didn't see you, said hermione, ron was, but he didn't be him. that was you, her from the dog, but they were have been a was nimbus two thousand. ron, ron, i'll be stupid, said harry, but ron was in the the floor, and and the - quidditch and a just and a, the eyes of the was broomstick, that was as they his long as they were no with a hands, and they had a knocked. the went to a time to have a the between. the whole of the troll, the floor. you've got to see you, you're a'd seen, harry, said ron. he's got the the school, said harry. i don't a a get it. you don't see you, said harry. the nimbus two thousand. potter, said ron. i'm, but you're a you around, i know you're. you're a, said dumbledore. harry had about the found a which were they looked at up. harry's other. i don't see you, you're? said snape. i'm i've got to be seeker, i think that was be can you? i don't you you? said hermione. i'm told you, said harry. i've got to see\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(untokenize(generated).replace(\"\\\"\",\"\").split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "keras_script_gen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
